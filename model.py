from sklearn.impute import SimpleImputer
from sklearn.feature_selection import VarianceThreshold
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, cross_val_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from lightgbm import LGBMRegressor
from joblib import parallel_backend
import numpy as np
import pandas as pd
from tqdm import tqdm
from hoopstats import PlayerScraper


# Function to convert minutes to float
def convert_minutes_to_float(minutes_str):
    try:
        if isinstance(minutes_str, str):
            if ':' in minutes_str:  # Format 'MM:SS'
                minutes, seconds = map(int, minutes_str.split(':'))
                return minutes + seconds / 60
            else:  # Handle cases like '35' or other formats
                return float(minutes_str)
        return float(minutes_str)  # Handle non-string cases
    except ValueError:
        return 0.0  # Return 0 for invalid entries


# Function to fetch data for a player
def fetch_player_data(first_name, last_name, years):
    player_scraper = PlayerScraper(first_name=first_name, last_name=last_name)
    all_data = pd.DataFrame()

    print("Fetching data for multiple years...")
    for year in tqdm(years, desc="Fetching Data"):
        season_data = player_scraper.get_game_log_by_year(year)
        if season_data is not None:
            season_data['Year'] = year
            all_data = pd.concat([all_data, pd.DataFrame(season_data)], ignore_index=True)

    print("Data fetching complete.")
    return all_data


# Function for preprocessing data
def preprocess_data(data):
    print("Converting columns to correct data types...")
    data['MP'] = data['MP'].apply(convert_minutes_to_float)

    # List of columns to convert to numeric
    numeric_columns = [
        'PTS', 'AST', 'TRB', 'FG', 'FGA', '3P', '3PA', 
        'FT', 'FTA', 'ORB', 'DRB', 'STL', 'BLK', 'TOV', 
        'PF', 'GmSc'
    ]

    # Convert specified columns to numeric and handle errors
    for col in numeric_columns:
        if col in ['3P%', 'FT%']:
            # Strip any spaces and remove percentage sign, then convert to float
            data[col] = data[col].str.strip().str.replace('%', '', regex=False)
            data[col] = pd.to_numeric(data[col], errors='coerce') / 100.0
        else:
            data[col] = pd.to_numeric(data[col], errors='coerce')
    # Drop rows with any NaN values after conversion
    data.dropna(subset=numeric_columns, inplace=True)

    # Convert columns to numeric
    data['PTS'] = pd.to_numeric(data['PTS'], errors='coerce')
    data['AST'] = pd.to_numeric(data['AST'], errors='coerce')
    data['REB'] = pd.to_numeric(data['TRB'], errors='coerce')
    data['FG%'] = pd.to_numeric(data['FG%'], errors='coerce')

    # Drop rows with zero values in PTS, AST, REB
    data = data[(data['PTS'] != 0) & (data['AST'] != 0) & (data['REB'] != 0)].copy()

    # Drop any remaining NaNs generated during conversion
    data.dropna(inplace=True)

    # Encode categorical data with one-hot encoding
    print("Encoding categorical data...")
    data = pd.get_dummies(data, columns=['Opp'], drop_first=True)

    # Feature Engineering: Moving averages
    print("Calculating rolling averages...")
    window_sizes = [5, 10, 15, 30]
    for window in window_sizes:
        data[f'rolling_avg_points_{window}'] = data['PTS'].rolling(window=window).mean().shift(1)
        data[f'rolling_avg_assists_{window}'] = data['AST'].rolling(window=window).mean().shift(1)
        data[f'rolling_avg_rebounds_{window}'] = data['REB'].rolling(window=window).mean().shift(1)

    # Calculate season averages
    season_averages = data.groupby('Year').agg(
        season_avg_points=('PTS', 'mean'),
        season_avg_assists=('AST', 'mean'),
        season_avg_rebounds=('REB', 'mean')
    ).reset_index()

    # Merge season averages back to the main DataFrame
    data = data.merge(season_averages, on='Year', how='left')

    # Dropping rows with NaNs generated by rolling calculations
    rolling_columns = [f'rolling_avg_points_{window}' for window in window_sizes]
    if all(col in data.columns for col in rolling_columns):
        data.dropna(subset=rolling_columns, inplace=True)

    print("Data preprocessing complete.")
    print(f"Data shape after processing: {data.shape}")
    return data


# Define the train_models function
def train_models(X, y):
    # Define models for ensemble learning
    models = {
        'lgb': LGBMRegressor(random_state=42, verbose=-1),  # Set verbosity to -1
        'rf': RandomForestRegressor(random_state=42),
        'gbr': GradientBoostingRegressor(random_state=42),
        'svr': SVR(),
        'ridge': make_pipeline(StandardScaler(), Ridge(alpha=1.0)),
        'mlp': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
    }

    # Combine all models into a stacking model
    stacked_model = StackingRegressor(estimators=[
        ('lgb', models['lgb']),
        ('rf', models['rf']),
        ('gbr', models['gbr']),
        ('svr', models['svr']),
        ('ridge', models['ridge']),
        ('mlp', models['mlp'])
    ], final_estimator=LinearRegression())

    # TimeSeriesSplit for cross-validation
    tscv = TimeSeriesSplit(n_splits=3)

    print("Training stacked model...")
    stacked_model.fit(X, y)

    return stacked_model


# Function for backtesting
def backtest_model(model, X, y, target_name):
    predictions = model.predict(X)
    predictions = np.expm1(predictions)  # Inverse log transformation
    mse = mean_squared_error(np.expm1(y), predictions)
    print(f"Backtesting MSE for {target_name}: {mse:.2f}")


# Function for predictions
def predict_upcoming_game(model, upcoming_game):
    prediction = model.predict(upcoming_game)
    prediction = np.expm1(prediction)  # Inverse log transformation
    return prediction

# Main script execution
if __name__ == "__main__":
    # Initialize parameters
    player_first_name = "Luka"
    player_last_name = "Doncic"
    years = range(2019, 2025)

    # Fetch and preprocess data
    all_data = fetch_player_data(player_first_name, player_last_name, years)
    all_data = preprocess_data(all_data)

    # Define features
    features = [
        'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 
        'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'STL', 
        'BLK', 'TOV', 'PF', 'GmSc',
        'rolling_avg_points_5', 'rolling_avg_assists_5', 'rolling_avg_rebounds_5',
        'rolling_avg_points_10', 'rolling_avg_assists_10', 'rolling_avg_rebounds_10',
        'rolling_avg_points_15', 'rolling_avg_assists_15', 'rolling_avg_rebounds_15',
        'rolling_avg_points_30', 'rolling_avg_assists_30', 'rolling_avg_rebounds_30',
        'season_avg_points', 'season_avg_assists', 'season_avg_rebounds'
    ]

    # Apply VarianceThreshold to select features with sufficient variance
    print("Applying Variance Threshold...")
    selector = VarianceThreshold(threshold=0.01)
    X = all_data[features]
    X_selected = X.loc[:, selector.fit(X).get_support()]  # Keep it as a DataFrame

    # Targets
    targets = ['PTS', 'AST', 'REB']
    models = {}

    # Train models for each target
    for target in tqdm(targets, desc="Training models", unit="model"):
        y = np.log1p(all_data[target])  # Log transformation of targets
        model = train_models(X_selected, y)

        # Store the model
        models[f"{target}_stacked"] = model

    # Prepare the upcoming game input as a DataFrame
    upcoming_game = pd.DataFrame({
        'MP': [all_data['MP'].iloc[-1]],
        'FG': [all_data['FG'].iloc[-1]],
        'FGA': [all_data['FGA'].iloc[-1]],
        'FG%': [all_data['FG%'].iloc[-1]],
        '3P': [all_data['3P'].iloc[-1]],
        '3PA': [all_data['3PA'].iloc[-1]],
        '3P%': [all_data['3P%'].iloc[-1]],
        'FT': [all_data['FT'].iloc[-1]],
        'FTA': [all_data['FTA'].iloc[-1]],
        'FT%': [all_data['FT%'].iloc[-1]],
        'ORB': [all_data['ORB'].iloc[-1]],
        'DRB': [all_data['DRB'].iloc[-1]],
        'TRB': [all_data['TRB'].iloc[-1]],
        'STL': [all_data['STL'].iloc[-1]],
        'BLK': [all_data['BLK'].iloc[-1]],
        'TOV': [all_data['TOV'].iloc[-1]],
        'PF': [all_data['PF'].iloc[-1]],
        'GmSc': [all_data['GmSc'].iloc[-1]],
        'rolling_avg_points_5': [all_data['rolling_avg_points_5'].iloc[-1]],
        'rolling_avg_assists_5': [all_data['rolling_avg_assists_5'].iloc[-1]],
        'rolling_avg_rebounds_5': [all_data['rolling_avg_rebounds_5'].iloc[-1]],
        'rolling_avg_points_10': [all_data['rolling_avg_points_10'].iloc[-1]],
        'rolling_avg_assists_10': [all_data['rolling_avg_assists_10'].iloc[-1]],
        'season_avg_points': [all_data['season_avg_points'].iloc[-1]],
        'season_avg_assists': [all_data['season_avg_assists'].iloc[-1]],
        'season_avg_rebounds': [all_data['season_avg_rebounds'].iloc[-1]]
    }).astype(float)

    # One-hot encode the upcoming game
    upcoming_game = pd.get_dummies(upcoming_game, drop_first=True)

    # Reindex to match X_selected's columns
    upcoming_game = upcoming_game.reindex(columns=X_selected.columns, fill_value=0)

    # Make predictions
    for target in targets:
        prediction = models[f"{target}_stacked"].predict(upcoming_game)  # Use the stacked model for prediction
        print(f"Predicted {target} for the upcoming game: {prediction[0]:.2f}")